import os
import tempfile
import streamlit as st
from langchain_community.vectorstores import FAISS
from utils import ClovaEmbeddings, build_document_from_image
from dotenv import load_dotenv

load_dotenv()

CLOVA_EMBED_API_URL = os.getenv("CLOVA_EMBED_API_URL")
CLOVA_API_KEY = os.getenv("CLOVA_API_KEY")

if not CLOVA_EMBED_API_URL or not CLOVA_API_KEY:
    st.error("âŒ .env íŒŒì¼ì—ì„œ CLOVA API ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

embeddings = ClovaEmbeddings(api_url=CLOVA_EMBED_API_URL, api_key=CLOVA_API_KEY)
INDEX_DIR = "faiss_index"

st.title("ğŸ“· ì´ë¯¸ì§€ ê¸°ë°˜ RAG ê²€ìƒ‰ ë°ëª¨")
st.caption("ì´ë¯¸ì§€ â†’ í…ìŠ¤íŠ¸(OCR) ë³€í™˜ â†’ CLOVA ì„ë² ë”© â†’ FAISS ê²€ìƒ‰")

tab1, tab2 = st.tabs(["ğŸ“¥ ì¸ë±ìŠ¤ ë§Œë“¤ê¸°", "ğŸ” ê²€ìƒ‰í•˜ê¸°"])

with tab1:
    st.header("ì´ë¯¸ì§€ ì—…ë¡œë“œ & ì¸ë±ì‹±")
    uploaded_files = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"], accept_multiple_files=True)
    if st.button("ì¸ë±ì‹± ì‹¤í–‰") and uploaded_files:
        docs = []
        for file in uploaded_files:
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp:
                tmp.write(file.read())
                tmp_path = tmp.name
            doc = build_document_from_image(tmp_path)
            docs.append(doc)

        if os.path.exists(INDEX_DIR):
            db = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
            db.add_documents(docs)
        else:
            db = FAISS.from_documents(docs, embeddings)
        db.save_local(INDEX_DIR)
        st.success(f"{len(docs)}ê°œì˜ ì´ë¯¸ì§€ê°€ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤.")

with tab2:
    st.header("ì´ë¯¸ì§€ ê²€ìƒ‰")
    query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if st.button("ê²€ìƒ‰ ì‹¤í–‰") and query:
        if not os.path.exists(INDEX_DIR):
            st.error("âŒ ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì¸ë±ì‹±í•˜ì„¸ìš”.")
        else:
            db = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
            results = db.similarity_search(query, k=5)
            for r in results:
                st.image(r.metadata["source"], caption=r.page_content[:100] + "...")
