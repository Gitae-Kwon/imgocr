# app.py
# -*- coding: utf-8 -*-
# Snap2Search â€” Google Vision OCR â†’ CLOVA Embedding v2 â†’ ì½”ì‚¬ì¸ ê²€ìƒ‰ (ê²½ëŸ‰)

import os, json, uuid, tempfile, http.client
import numpy as np
import streamlit as st
from PIL import Image

# ===================== Secrets =====================
# Secrets.toml ì˜ˆì‹œëŠ” ì•„ë˜ì— ë”°ë¡œ ì²¨ë¶€
CLOVA_API_KEY = st.secrets.get("CLOVA_API_KEY", "")  # ì˜ˆ: "Bearer nv-********"
CLOVA_HOST = st.secrets.get("CLOVA_HOST", "clovastudio.stream.ntruss.com")
GCP_SA_INFO = st.secrets.get("gcp_service_account", None)

if not CLOVA_API_KEY:
    st.error("âŒ Secretsì— CLOVA_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆ) 'Bearer nv-***'")
    st.stop()
if not GCP_SA_INFO:
    st.error("âŒ Secretsì— [gcp_service_account] ë¸”ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

# ===================== ì¸ë±ìŠ¤ ê²½ë¡œ =================
INDEX_DIR = "index"
VEC_PATH = os.path.join(INDEX_DIR, "index.npy")    # (N, D)
META_PATH = os.path.join(INDEX_DIR, "meta.json")   # [{"source":..., "text":...}, ...]
os.makedirs(INDEX_DIR, exist_ok=True)

# ===================== ì„¸ì…˜ ìƒíƒœ ====================
if "uploads" not in st.session_state:
    st.session_state["uploads"] = []  # [{"name":..., "type":..., "data": b"..."}]

def _store_upload():
    files = st.session_state.get("uploader_main")
    saved = []
    if files:
        for f in files:
            saved.append({"name": f.name, "type": f.type, "data": f.getvalue()})
    st.session_state["uploads"] = saved

# ===================== Google Vision OCR =================
@st.cache_resource
def get_vision_client():
    from google.cloud import vision
    # st.secrets ì˜ dictë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    return vision.ImageAnnotatorClient.from_service_account_info(dict(GCP_SA_INFO))

def vision_ocr_extract(tmp_path: str, use_document: bool = True) -> str:
    """Google Vision OCR. ë¬¸ì„œ/ì˜ìˆ˜ì¦ì€ document_text_detectionì´ ë” ì •í™•."""
    from google.cloud import vision
    client = get_vision_client()

    with open(tmp_path, "rb") as f:
        content = f.read()
    image = vision.Image(content=content)

    # í•œêµ­ì–´/ì˜ì–´ íŒíŠ¸
    img_ctx = vision.ImageContext(language_hints=["ko", "en"])

    if use_document:
        resp = client.document_text_detection(image=image, image_context=img_ctx)
    else:
        resp = client.text_detection(image=image, image_context=img_ctx)

    if resp.error.message:
        return f"(OCR ì˜¤ë¥˜) {resp.error.message}"

    ann = getattr(resp, "full_text_annotation", None)
    return (ann.text if ann and ann.text else "").strip()

# ===================== CLOVA v2 ì„ë² ë”© ====================
def clova_embed(text: str) -> np.ndarray:
    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": CLOVA_API_KEY,
        "X-NCP-CLOVASTUDIO-REQUEST-ID": uuid.uuid4().hex,
    }
    payload = {"text": text}
    conn = http.client.HTTPSConnection(CLOVA_HOST)
    conn.request("POST", "/v1/api-tools/embedding/v2", json.dumps(payload), headers)
    res = conn.getresponse()
    data = json.loads(res.read().decode("utf-8"))
    conn.close()
    if data.get("status", {}).get("code") != "20000":
        raise RuntimeError(f"CLOVA embedding error: {data}")
    return np.asarray(data["result"]["embedding"], dtype=np.float32)

# ===================== ì¸ë±ìŠ¤ IO / ê²€ìƒ‰ ===================
def load_index():
    if not (os.path.exists(VEC_PATH) and os.path.exists(META_PATH)):
        return None, []
    return np.load(VEC_PATH), json.load(open(META_PATH, "r", encoding="utf-8"))

def save_index(vecs: np.ndarray, meta: list):
    np.save(VEC_PATH, vecs)
    with open(META_PATH, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

def add_documents(docs: list):
    # docs: [{"source": <tmp_path>, "text": <ocr_text>}]
    new_vecs = []
    for d in docs:
        v = clova_embed(d["text"])
        v = v / (np.linalg.norm(v) + 1e-12)   # ì½”ì‚¬ì¸ìš© ì •ê·œí™”
        new_vecs.append(v)
    new_vecs = np.stack(new_vecs, axis=0)

    old_vecs, old_meta = load_index()
    if old_vecs is None:
        save_index(new_vecs, docs)
    else:
        save_index(np.vstack([old_vecs, new_vecs]), old_meta + docs)

def search(query: str, k: int = 5):
    vecs, meta = load_index()
    if vecs is None or len(meta) == 0:
        return []
    q = clova_embed(query)
    q = q / (np.linalg.norm(q) + 1e-12)
    sims = vecs @ q
    idx = np.argsort(-sims)[:k]
    return [(float(sims[i]), meta[i]) for i in idx]

# ===================== UI ================================
st.set_page_config(page_title="Snap2Search (Vision + CLOVA)", page_icon="ğŸ“·", layout="wide")
st.title("ğŸ“· Snap2Search â€” Google Vision OCR â†’ CLOVA ì„ë² ë”© â†’ ì½”ì‚¬ì¸ ê²€ìƒ‰")

tab1, tab2 = st.tabs(["ğŸ“¥ ì¸ë±ìŠ¤ ë§Œë“¤ê¸°", "ğŸ” ê²€ìƒ‰í•˜ê¸°"])

with tab1:
    st.subheader("ì´ë¯¸ì§€ ì—…ë¡œë“œ & ì¸ë±ì‹±")
    files_widget = st.file_uploader(
        "ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥)",
        type=["jpg","jpeg","png","webp","heic","HEIC","pdf"],
        accept_multiple_files=True,
        key="uploader_main",
        on_change=_store_upload
    )
    st.caption(f"ì—…ë¡œë“œ ëœ íŒŒì¼ ìˆ˜: {len(st.session_state['uploads'])}")
    if st.session_state["uploads"]:
        st.info([x["name"] for x in st.session_state["uploads"]][:10])

    if st.button("ì¸ë±ì‹± ì‹¤í–‰", use_container_width=True):
        if not st.session_state["uploads"]:
            st.warning("ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            docs = []
            with st.spinner("ğŸ” Vision OCR ë° ì„ë² ë”© ì¤‘..."):
                for up in st.session_state["uploads"]:
                    # ì„¸ì…˜ ë°”ì´íŠ¸ â†’ ì„ì‹œ íŒŒì¼
                    suffix = os.path.splitext(up["name"])[1] or ".jpg"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(up["data"])
                        tmp_path = tmp.name

                    # ì‚¬ì§„/ë¼ë²¨ì€ text_detectionìœ¼ë¡œ ë°”ê¾¸ê³  ì‹¶ìœ¼ë©´ Falseë¡œ
                    text = vision_ocr_extract(tmp_path, use_document=True)
                    if not text:
                        text = f"filename: {os.path.basename(tmp_path)}"
                    docs.append({"source": tmp_path, "text": text})

                add_documents(docs)

            st.success(f"âœ… {len(docs)}ê°œ ì´ë¯¸ì§€ ì¸ë±ì‹± ì™„ë£Œ")
            with st.expander("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°"):
                for d in docs:
                    st.write(f"**{os.path.basename(d['source'])}**")
                    st.code(d["text"][:800] + ("..." if len(d["text"]) > 800 else ""))

with tab2:
    st.subheader("ìì—°ì–´ë¡œ ê²€ìƒ‰")
    q = st.text_input("ì˜ˆ: 'ë§¤ì¼ ë‘ìœ  99.9', 'ì„¤íƒ• ë¬´ì²¨ê°€ 9.0g'")
    k = st.slider("ê²°ê³¼ ìˆ˜ (k)", 1, 10, 5)

    cols = st.columns(2)
    with cols[0]:
        if st.button("ì¸ë±ìŠ¤ ì´ˆê¸°í™”", use_container_width=True):
            try:
                if os.path.exists(VEC_PATH): os.remove(VEC_PATH)
                if os.path.exists(META_PATH): os.remove(META_PATH)
                st.success("ğŸ§¹ ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                st.error("ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜")
                st.exception(e)

    if st.button("ê²€ìƒ‰ ì‹¤í–‰", use_container_width=True):
        if not q.strip():
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            try:
                with st.spinner("ğŸ” ê²€ìƒ‰ ì¤‘..."):
                    results = search(q, k=k)
                if not results:
                    st.info("ì¸ë±ìŠ¤ê°€ ë¹„ì—ˆê±°ë‚˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    for score, m in results:
                        st.markdown("---")
                        if os.path.exists(m["source"]):
                            st.image(m["source"], caption=os.path.basename(m["source"]), use_column_width=True)
                        st.caption(f"ìœ ì‚¬ë„: {score:.4f}")
                        st.code(m["text"][:800] + ("..." if len(m["text"]) > 800 else ""))
            except Exception as e:
                st.error("ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.exception(e)
