# app.py
# -*- coding: utf-8 -*-
import os
import json
import uuid
import tempfile
import http.client
import requests

import streamlit as st
from PIL import Image

from langchain.embeddings.base import Embeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document

# -----------------------------
# í™˜ê²½ë³€ìˆ˜: Streamlit Secretsì—ì„œ ì½ê¸°
# -----------------------------
CLOVA_API_KEY = st.secrets.get("CLOVA_API_KEY", "")
CLOVA_HOST = st.secrets.get("CLOVA_HOST", "clovastudio.stream.ntruss.com")
OCR_SPACE_API_KEY = st.secrets.get("OCR_SPACE_API_KEY", "")

if not CLOVA_API_KEY:
    st.error("âŒ CLOVA_API_KEYê°€ secrets.tomlì— ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# -----------------------------
# CLOVA v2 ìž„ë² ë”© ì‹¤í–‰ê¸°
# -----------------------------
class CompletionExecutor:
    def __init__(self, host: str, api_key: str, request_id: str):
        self._host = host
        self._api_key = api_key
        self._request_id = request_id

    def _send_request(self, completion_request: dict):
        headers = {
            "Content-Type": "application/json; charset=utf-8",
            "Authorization": self._api_key,
            "X-NCP-CLOVASTUDIO-REQUEST-ID": self._request_id,
        }
        conn = http.client.HTTPSConnection(self._host)
        conn.request("POST", "/v1/api-tools/embedding/v2", json.dumps(completion_request), headers)
        response = conn.getresponse()
        result = json.loads(response.read().decode("utf-8"))
        conn.close()
        return result

    def execute(self, completion_request: dict):
        res = self._send_request(completion_request)
        if isinstance(res, dict) and res.get("status", {}).get("code") == "20000":
            return res.get("result")
        return {"error": res}

class ClovaV2Embeddings(Embeddings):
    """LangChain Embeddings ì–´ëŒ‘í„° (v2, ë‹¨ê±´ í˜¸ì¶œ)"""
    def __init__(self, host: str, api_key: str):
        self.host = host
        self.api_key = api_key

    def _embed_one(self, text: str):
        executor = CompletionExecutor(
            host=self.host,
            api_key=self.api_key,
            request_id=uuid.uuid4().hex
        )
        payload = {"text": text}
        res = executor.execute(payload)
        if "error" in res:
            raise RuntimeError(f"CLOVA v2 embedding error: {res['error']}")
        if "embedding" in res:
            return res["embedding"]
        raise RuntimeError(f"Unexpected embedding response: {res}")

    def embed_query(self, text: str):
        return self._embed_one(text)

    def embed_documents(self, texts):
        return [self._embed_one(t) for t in texts]

# -----------------------------
# OCR.space ê¸°ë°˜ OCR
# -----------------------------
def extract_text_from_image(tmp_path: str) -> str:
    key = OCR_SPACE_API_KEY or "helloworld"  # demo í‚¤
    try:
        with open(tmp_path, "rb") as f:
            r = requests.post(
                "https://api.ocr.space/parse/image",
                files={"filename": f},
                data={"apikey": key, "language": "kor"},
                timeout=90,
            )
        r.raise_for_status()
        data = r.json()
        if data.get("IsErroredOnProcessing"):
            msg = data.get("ErrorMessage") or data.get("ErrorDetails")
            return f"(OCR ì‹¤íŒ¨) {msg}"
        results = data.get("ParsedResults")
        if not results:
            return "(OCR ê²°ê³¼ ì—†ìŒ)"
        return (results[0].get("ParsedText") or "").strip()
    except Exception as e:
        return f"(OCR ì˜ˆì™¸) {e}"

def build_document_from_image(tmp_path: str) -> Document:
    text = extract_text_from_image(tmp_path)
    if not text:
        text = f"filename: {os.path.basename(tmp_path)}"
    return Document(page_content=text, metadata={"source": tmp_path})

# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="Snap2Search (OCR.space + CLOVA v2)", page_icon="ðŸ“·", layout="wide")
st.title("ðŸ“· Snap2Search â€” ì´ë¯¸ì§€â†’í…ìŠ¤íŠ¸(OCR)â†’ìž„ë² ë”©(v2)â†’FAISS ê²€ìƒ‰")
st.caption("OCR.space + CLOVA Studio Embedding v2 + LangChain + FAISS")

# ìž„ë² ë”© ì¤€ë¹„
try:
    embeddings = ClovaV2Embeddings(host=CLOVA_HOST, api_key=CLOVA_API_KEY)
except Exception as e:
    st.error("âŒ CLOVA ìž„ë² ë”© ì´ˆê¸°í™” ì‹¤íŒ¨. secrets.toml ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.exception(e)
    st.stop()

INDEX_DIR = "faiss_index"

tab1, tab2 = st.tabs(["ðŸ“¥ ì¸ë±ìŠ¤ ë§Œë“¤ê¸°", "ðŸ” ê²€ìƒ‰í•˜ê¸°"])

with tab1:
    st.subheader("ì´ë¯¸ì§€ ì—…ë¡œë“œ & ì¸ë±ì‹±")
    uploaded_files = st.file_uploader(
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ìž¥ ê°€ëŠ¥)", type=["png", "jpg", "jpeg", "webp"], accept_multiple_files=True
    )
    if st.button("ì¸ë±ì‹± ì‹¤í–‰", use_container_width=True):
        if not uploaded_files:
            st.warning("ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            docs = []
            tmp_paths = []
            for f in uploaded_files:
                suffix = os.path.splitext(f.name)[1]
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    tmp.write(f.read())
                    tmp_paths.append(tmp.name)

            with st.spinner("ðŸ”Ž OCR ì²˜ë¦¬ ë° ìž„ë² ë”© ì¤‘..."):
                for p in tmp_paths:
                    doc = build_document_from_image(p)
                    docs.append(doc)

                if os.path.exists(INDEX_DIR):
                    db = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
                    db.add_documents(docs)
                else:
                    db = FAISS.from_documents(docs, embeddings)
                db.save_local(INDEX_DIR)

            st.success(f"âœ… {len(docs)}ê°œ ì´ë¯¸ì§€ ì¸ë±ì‹± ì™„ë£Œ")
            with st.expander("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°"):
                for d in docs:
                    st.write(f"**{os.path.basename(d.metadata['source'])}**")
                    st.code(d.page_content[:800] + ("..." if len(d.page_content) > 800 else ""))

with tab2:
    st.subheader("ìžì—°ì–´ë¡œ ê²€ìƒ‰")
    query = st.text_input("ì˜ˆ: 'ì˜ìˆ˜ì¦ì—ì„œ ì´ ê²°ì œ ê¸ˆì•¡' / 'ë¹¨ê°„ ë‚˜ì´í‚¤ ì‹ ë°œ' ë“±")
    topk = st.slider("ê°€ì ¸ì˜¬ ê²°ê³¼ ìˆ˜ (k)", 1, 10, 5)
    if st.button("ê²€ìƒ‰ ì‹¤í–‰", use_container_width=True):
        if not os.path.exists(INDEX_DIR):
            st.error("âŒ ë¨¼ì € ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        elif not query.strip():
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ðŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘..."):
                db = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
                results = db.similarity_search(query, k=topk)

            if not results:
                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for r in results:
                    st.markdown("---")
                    src = r.metadata.get("source")
                    if src and os.path.exists(src):
                        st.image(src, caption=os.path.basename(src), use_column_width=True)
                    st.caption("ì¶”ì¶œ í…ìŠ¤íŠ¸ (ì¼ë¶€)")
                    st.code(r.page_content[:800] + ("..." if len(r.page_content) > 800 else ""))
